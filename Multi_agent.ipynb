{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2ca0ae95bca40cdb8f51def9a44a995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e0df648d9c9415fb220bcc6a121f771",
              "IPY_MODEL_ba4483e14c1946e585923dfc88b17569",
              "IPY_MODEL_40f15245d45946a2a89edbb7362a5c7e"
            ],
            "layout": "IPY_MODEL_621f20e4c9944818832d000ec7d0af35"
          }
        },
        "3e0df648d9c9415fb220bcc6a121f771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0e032e643c4eea9aba3c623663b8fb",
            "placeholder": "​",
            "style": "IPY_MODEL_fa7fb5b1b379489d8b15bbe3a33773af",
            "value": ""
          }
        },
        "ba4483e14c1946e585923dfc88b17569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d575a28e5505431a861648b3d6e3f3d9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d135e1f6fbcb4c7589b62fa2b3a6d4f7",
            "value": 1
          }
        },
        "40f15245d45946a2a89edbb7362a5c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76a848035cf84f1fb09d4377bc73b89d",
            "placeholder": "​",
            "style": "IPY_MODEL_5259839d4bda478cb839273fd94116aa",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01&lt;00:00,  1.01s/it]\n"
          }
        },
        "621f20e4c9944818832d000ec7d0af35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0e032e643c4eea9aba3c623663b8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa7fb5b1b379489d8b15bbe3a33773af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d575a28e5505431a861648b3d6e3f3d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d135e1f6fbcb4c7589b62fa2b3a6d4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76a848035cf84f1fb09d4377bc73b89d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5259839d4bda478cb839273fd94116aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0b7cc99860c440992ec86102150f3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22f2a0e9f9ff4277b7895009862296b8",
              "IPY_MODEL_bd6362cdbbff484b8e40e7580df02c0f",
              "IPY_MODEL_9c017b7c32b94de49cd99bd676038d05"
            ],
            "layout": "IPY_MODEL_b32b48d4cc9f455fbc64ca5373916248"
          }
        },
        "22f2a0e9f9ff4277b7895009862296b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd993ccf2c7b4685b954f76c59814e68",
            "placeholder": "​",
            "style": "IPY_MODEL_b30d595c298a4114a98fbec6cb9401bf",
            "value": ""
          }
        },
        "bd6362cdbbff484b8e40e7580df02c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_787b7fc595fe4b62becf15c6857a02ef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_085c25aceb194fec933a001d7f3bbc99",
            "value": 1
          }
        },
        "9c017b7c32b94de49cd99bd676038d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbc4a977c65e4418999a0de9cebb149d",
            "placeholder": "​",
            "style": "IPY_MODEL_96ce228d6de645eda1a8726cef3fdafa",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00&lt;00:00,  1.03it/s]\n"
          }
        },
        "b32b48d4cc9f455fbc64ca5373916248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd993ccf2c7b4685b954f76c59814e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b30d595c298a4114a98fbec6cb9401bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787b7fc595fe4b62becf15c6857a02ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "085c25aceb194fec933a001d7f3bbc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbc4a977c65e4418999a0de9cebb149d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ce228d6de645eda1a8726cef3fdafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80669ad37b3247eeab419a230a93a555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9aa5547ea6a944c5bd48a8991fedf7cf",
              "IPY_MODEL_5e808942cda9472cbbb6aae8ece7cddc",
              "IPY_MODEL_2be5b9273a3d4a25878448670dd19b61"
            ],
            "layout": "IPY_MODEL_caff3af668c14701ac49e67615dfbfc2"
          }
        },
        "9aa5547ea6a944c5bd48a8991fedf7cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18965cdeb8a64992b939a0cae9695f21",
            "placeholder": "​",
            "style": "IPY_MODEL_54247a7437204504882ff62fea116940",
            "value": ""
          }
        },
        "5e808942cda9472cbbb6aae8ece7cddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9970226262f4f3aabc969d1b407f1b8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ba2499ccb89496699040f31fbbb94bb",
            "value": 1
          }
        },
        "2be5b9273a3d4a25878448670dd19b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e8cccb480c4ec1a6dcf00861632b72",
            "placeholder": "​",
            "style": "IPY_MODEL_16bb36d2c81b4791bb8cfd410f70a4c9",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:05&lt;00:00,  5.15s/it]\n"
          }
        },
        "caff3af668c14701ac49e67615dfbfc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18965cdeb8a64992b939a0cae9695f21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54247a7437204504882ff62fea116940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9970226262f4f3aabc969d1b407f1b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba2499ccb89496699040f31fbbb94bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4e8cccb480c4ec1a6dcf00861632b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16bb36d2c81b4791bb8cfd410f70a4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install pdfkit\n",
        "!sudo apt-get install wkhtmltopdf"
      ],
      "metadata": {
        "id": "jKmqnIK5Udh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb64680-792a-4990-f9e8-0960f59852e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.0.4)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.48.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.48.2)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (4.25.6)\n",
            "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.115.8)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.11)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.59.9)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.11/dist-packages (from vllm) (0.34.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.10.6)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (10.4.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.2)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.7.0)\n",
            "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.9)\n",
            "Requirement already satisfied: outlines==0.1.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.11)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.2.2)\n",
            "Requirement already satisfied: xgrammar>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.11)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.17.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.1.1.post5)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm) (24.0.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n",
            "Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.6.1)\n",
            "Requirement already satisfied: mistral_common>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common[opencv]>=1.5.0->vllm) (1.5.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.0)\n",
            "Requirement already satisfied: compressed-tensors==0.9.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\n",
            "Requirement already satisfied: depyf==0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.18.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (2.42.0)\n",
            "Requirement already satisfied: nvidia-ml-py>=12.560.30 in /usr/local/lib/python3.11/dist-packages (from vllm) (12.570.86)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio==2.5.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.20.1+cu124)\n",
            "Requirement already satisfied: xformers==0.0.28.post3 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.0.28.post3)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.3.9)\n",
            "Requirement already satisfied: interegular in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (3.1.5)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
            "Requirement already satisfied: airportsdata in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (20241001)\n",
            "Requirement already satisfied: outlines_core==0.1.26 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.45.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.2)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral_common[opencv]>=1.5.0->vllm) (4.11.0.86)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->ray[default]>=2.9->vllm) (1.5.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (0.5.6)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (0.11.4)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (7.1.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (20.29.1)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default]>=2.9->vllm) (1.70.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.4.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2024.12.14)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.19.1->vllm) (0.27.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.48.2->vllm) (0.5.2)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from xgrammar>=0.1.6->vllm) (2.13.6)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from xgrammar>=0.1.6->vllm) (8.3.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (14.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.52.0->vllm) (1.0.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.22.3)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.9->vllm) (4.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default]>=2.9->vllm) (0.1.3)\n",
            "Requirement already satisfied: six~=1.16 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default]>=2.9->vllm) (1.17.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default]>=2.9->vllm) (2.19.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->xgrammar>=0.1.6->vllm) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->xgrammar>=0.1.6->vllm) (1.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open->ray[default]>=2.9->vllm) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (1.26.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (2.27.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.9->vllm) (0.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pdfkit in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wkhtmltopdf is already the newest version (0.12.6-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():from vllm import LLM, SamplingParams\n",
        "import torch\n",
        "\n",
        "class CompetitorFinderAgent:\n",
        "    def __init__(self, model_name=\"Qwen/Qwen2.5-0.5B-Instruct\", tensor_parallel_size=1, max_model_len=2048, max_tokens=512, temperature=0.7, top_p=0.9, device=\"cuda\"):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.llm = LLM(\n",
        "            model_name,\n",
        "            tensor_parallel_size=tensor_parallel_size,\n",
        "            gpu_memory_utilization=0.95,\n",
        "            trust_remote_code=True,\n",
        "            dtype=\"half\",\n",
        "            enforce_eager=True,\n",
        "            max_model_len=max_model_len,\n",
        "            device=device\n",
        "        )\n",
        "        self.tokenizer = self.llm.get_tokenizer()\n",
        "        self.sampling_params = SamplingParams(\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "\n",
        "    def find_competitors(self, input_query, N=3):\n",
        "        prompt = (\n",
        "            f\"Identify {N} major competitors for the following product, service, or industry: \\\"{input_query}\\\". \"\n",
        "            \"Provide only the names of the competitors in a numbered list.\"\n",
        "        )\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a market research expert.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "        text = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        response = self.llm.generate([text], sampling_params=self.sampling_params)\n",
        "        raw_output = response[0].outputs[0].text\n",
        "\n",
        "        print(\"\\n\\nModel response:\")\n",
        "        print(raw_output)\n",
        "        print(\"=\"*50, \"\\n\\n\")\n",
        "\n",
        "\n",
        "        competitors = [line.split(\". \", 1)[1].strip() for line in raw_output.splitlines() if line[0].isdigit() and \". \" in line]\n",
        "        return competitors\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "finder = CompetitorFinderAgent(model_name, device=\"cuda\")\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    print(\"Opps... CUDA not available, change the runtime to GPU\")\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz5ovOIzakV3",
        "outputId": "9c5c81b2-46e2-4bc5-be81-a3c76f54bb9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opps... CUDA not available, change the runtime to GPU\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVsNaOa9CPqR",
        "outputId": "5d28cf08-2556-467b-b47e-8b8b544c31ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM\n"
          ]
        }
      ],
      "source": [
        "input_query = \"LLM\"\n",
        "print(input_query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "competitors = finder.find_competitors(input_query)\n",
        "print(f\"Competitors for '{input_query}':\")\n",
        "print(competitors)"
      ],
      "metadata": {
        "id": "yLyze8yAsOMX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del finder"
      ],
      "metadata": {
        "id": "crPQ8Isgqu2X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "class WebScraper:\n",
        "    def __init__(self, user_agent=None):\n",
        "        self.user_agent = user_agent or \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "        self.headers = {\"User-Agent\": self.user_agent}\n",
        "\n",
        "    def google_search_scrape(self, query, websites, num_results=10):\n",
        "        search_results = []\n",
        "        for website in websites:\n",
        "            search_query = f\"{query} {website}\"\n",
        "            search_url = f\"https://www.google.com/search?q={search_query.replace(' ', '+')}&num={num_results}\"\n",
        "            response = requests.get(search_url, headers=self.headers)\n",
        "\n",
        "            if response.status_code != 200:\n",
        "                print(f\"Error fetching search results for {search_query}: {response.status_code}\")\n",
        "                continue\n",
        "\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            for g in soup.find_all('div', class_='tF2Cxc'):\n",
        "                title = g.find('h3').text if g.find('h3') else \"No Title\"\n",
        "                link = g.find('a')['href'] if g.find('a') else \"No Link\"\n",
        "                search_results.append({\"website\": website, \"title\": title, \"link\": link})\n",
        "\n",
        "        return search_results\n",
        "\n",
        "    def scrape_page_content(self, url):\n",
        "        response = requests.get(url, headers=self.headers)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            paragraphs = soup.find_all('p')\n",
        "            return \" \".join([p.text for p in paragraphs])\n",
        "        else:\n",
        "            print(f\"Failed to fetch {url}\")\n",
        "            return \"\"\n",
        "\n",
        "    def get_content_from_query(self, query, websites):\n",
        "        search_results = self.google_search_scrape(query, websites, num_results=5)\n",
        "\n",
        "        final_content = \"\"\n",
        "        for result in search_results:\n",
        "            content = self.scrape_page_content(result[\"link\"])\n",
        "            if len(content) < 20:\n",
        "              continue\n",
        "\n",
        "            final_content += content + \"\\n\"\n",
        "\n",
        "        return final_content\n",
        "\n",
        "scraper = WebScraper()"
      ],
      "metadata": {
        "id": "Sb-7kyO9dUuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"information about Pizza\"\n",
        "websites = [\"\", \"site:g2.com\"]\n",
        "scapped_data = []\n",
        "for competitor in competitors:\n",
        "    query = f\"information about {competitor}\"\n",
        "    content = scraper.get_content_from_query(query, websites)\n",
        "    scapped_data.append(content)\n",
        "    print(content)\n",
        "    print(\"=\"*50, \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwHQ5fyddf7z",
        "outputId": "727c0815-764f-4739-d3ee-14dcabadb0cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================== \n",
            "\n",
            "\n",
            "\n",
            "================================================== \n",
            "\n",
            "\n",
            "\n",
            "================================================== \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "import torch\n",
        "\n",
        "class CompetitorInfoExtractor:\n",
        "    def __init__(self, model_name=\"Qwen/Qwen2.5-0.5B-Instruct\", tensor_parallel_size=1, max_model_len=32768, max_tokens=16384, temperature=0.7, top_p=0.9, device=\"cuda\"):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.llm = LLM(\n",
        "            model_name,\n",
        "            tensor_parallel_size=tensor_parallel_size,\n",
        "            gpu_memory_utilization=0.95,\n",
        "            trust_remote_code=True,\n",
        "            dtype=\"half\",\n",
        "            enforce_eager=True,\n",
        "            max_model_len=max_model_len,\n",
        "            device=device\n",
        "        )\n",
        "        self.tokenizer = self.llm.get_tokenizer()\n",
        "\n",
        "        self.sampling_params = SamplingParams(\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "\n",
        "    def extract_info(self, competitors, texts, max_len=20000):\n",
        "        prompts = [\n",
        "            f\"Extract relevant information about {competitor}, from the provided text. \"\n",
        "            \"Remove unnecessary data and handle any conflicts by choosing the most reliable and relevant details. \"\n",
        "            \"Ensure high data accuracy.\\n\\n\"\n",
        "            f\"Text:\\n{text[:max_len]}\\n\\n\"\n",
        "            for competitor, text in zip(competitors, texts)\n",
        "        ]\n",
        "\n",
        "        messages_batch = [\n",
        "            [{\"role\": \"system\", \"content\": \"You are a helpful assistant capable of analyzing data and extracting relevant information. \"\n",
        "                                          \"Extract information from the provided text, removing any unnecessary or irrelevant details. \"\n",
        "                                          \"Handle data conflicts by selecting the most reliable and accurate details.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}]\n",
        "            for prompt in prompts\n",
        "        ]\n",
        "\n",
        "        texts_batch = [self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) for messages in messages_batch]\n",
        "\n",
        "        responses = self.llm.generate(texts_batch, sampling_params=self.sampling_params)\n",
        "\n",
        "        extracted_info = []\n",
        "        for i, response in enumerate(responses):\n",
        "            response_text = response.outputs[0].text\n",
        "            extracted_info.append(response_text)\n",
        "\n",
        "        return extracted_info\n",
        "\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "extractor = CompetitorInfoExtractor(model_name, device=\"cuda\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357,
          "referenced_widgets": [
            "80669ad37b3247eeab419a230a93a555",
            "9aa5547ea6a944c5bd48a8991fedf7cf",
            "5e808942cda9472cbbb6aae8ece7cddc",
            "2be5b9273a3d4a25878448670dd19b61",
            "caff3af668c14701ac49e67615dfbfc2",
            "18965cdeb8a64992b939a0cae9695f21",
            "54247a7437204504882ff62fea116940",
            "c9970226262f4f3aabc969d1b407f1b8",
            "9ba2499ccb89496699040f31fbbb94bb",
            "a4e8cccb480c4ec1a6dcf00861632b72",
            "16bb36d2c81b4791bb8cfd410f70a4c9"
          ]
        },
        "id": "RQeij82k5-wz",
        "outputId": "9ce76e3d-e9b7-48c3-e474-07b0ccace6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 02-04 08:09:00 config.py:2368] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 02-04 08:09:00 config.py:526] This model supports multiple tasks: {'generate', 'score', 'embed', 'classify', 'reward'}. Defaulting to 'generate'.\n",
            "WARNING 02-04 08:09:00 cuda.py:100] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
            "WARNING 02-04 08:09:00 config.py:662] Async output processing is not supported on the current platform type cuda.\n",
            "INFO 02-04 08:09:00 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='Qwen/Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-0.5B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n",
            "INFO 02-04 08:09:01 model_runner.py:1111] Starting to load model Qwen/Qwen2.5-0.5B-Instruct...\n",
            "INFO 02-04 08:09:01 weight_utils.py:251] Using model weights format ['*.safetensors']\n",
            "INFO 02-04 08:09:02 weight_utils.py:296] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80669ad37b3247eeab419a230a93a555"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-04 08:09:07 model_runner.py:1116] Loading model weights took 0.9228 GB\n",
            "INFO 02-04 08:09:09 worker.py:266] Memory profiling takes 1.73 seconds\n",
            "INFO 02-04 08:09:09 worker.py:266] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.95) = 14.00GiB\n",
            "INFO 02-04 08:09:09 worker.py:266] model weights take 0.92GiB; non_torch_memory takes 0.00GiB; PyTorch activation peak memory takes 1.43GiB; the rest of the memory reserved for KV Cache is 11.65GiB.\n",
            "INFO 02-04 08:09:10 executor_base.py:108] # CUDA blocks: 63616, # CPU blocks: 21845\n",
            "INFO 02-04 08:09:10 executor_base.py:113] Maximum concurrency for 32768 tokens per request: 31.06x\n",
            "INFO 02-04 08:09:11 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 3.33 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# competitors = [\"Intercom\"]\n",
        "# competitor_info_list = [content]\n",
        "\n",
        "competitor_info_list = extractor.extract_info(competitors, scapped_data, max_len = 20000)\n",
        "for competitor_info in competitor_info_list:\n",
        "    print(\"\\n\", \"==\"*50, \"\\n\", competitor_info, \"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpaic78adAN7",
        "outputId": "7bc42f3e-1328-4260-eea8-98261a54c9f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s, est. speed input: 112.41 toks/s, output: 130.93 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ==================================================================================================== \n",
            " Apple is a multinational technology company headquartered in Cupertino, California, USA. The company produces and sells a wide range of consumer electronics, including smartphones, tablets, laptops, and other devices. Apple is known for its user-friendly interface, innovative products, and strong brand identity. The company is also involved in various industries, including software development, healthcare, and renewable energy. Apple has been a leader in the technology industry for over 50 years and is known for its commitment to innovation and customer satisfaction. \n",
            "\n",
            "\n",
            "\n",
            " ==================================================================================================== \n",
            " Amazon is a multinational technology and retail company that operates as a publicly traded company on the NASDAQ Stock Market. The company's primary focus is on the creation, production, and sale of electronic products, including computers, televisions, and other electronic devices. Amazon is headquartered in Seattle, Washington, and has branches in various other locations around the world. The company has a wide range of products and services, including e-commerce, online shopping, and cloud computing. Amazon is known for its focus on customer satisfaction, with a strong emphasis on convenience and speed in product delivery. \n",
            "\n",
            "\n",
            "\n",
            " ==================================================================================================== \n",
            " Microsoft is a multinational technology company headquartered in Redmond, Washington, USA. The company offers a wide range of products and services, including software, hardware, and services. Microsoft has a strong focus on innovation, user experience, and productivity, and it is known for its Windows operating system, Azure cloud platform, and Office suite of applications. Microsoft also has a presence in the fields of artificial intelligence, biotechnology, and artificial intelligence. \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del extractor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwofhZj8gqHL",
        "outputId": "19c92dc5-09f8-4251-8853-900a630a3111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "import torch\n",
        "\n",
        "class CompetitorProfileAgent:\n",
        "    def __init__(self, model_name=\"Qwen/Qwen2.5-0.5B-Instruct\", tensor_parallel_size=1, max_model_len=32768, max_tokens=16384, temperature=0.7, top_p=0.9, device=\"cuda\"):\n",
        "        torch.cuda.empty_cache()\n",
        "        self.llm = LLM(\n",
        "            model_name,\n",
        "            tensor_parallel_size=tensor_parallel_size,\n",
        "            gpu_memory_utilization=0.95,\n",
        "            trust_remote_code=True,\n",
        "            dtype=\"half\",\n",
        "            enforce_eager=True,\n",
        "            max_model_len=max_model_len,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        self.tokenizer = self.llm.get_tokenizer()\n",
        "\n",
        "        self.sampling_params = SamplingParams(\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "\n",
        "    def generate_profile(self, competitors, competitor_info_list):\n",
        "        profiles = []\n",
        "\n",
        "        prompts = [\n",
        "            f\"Analyze the following information about {competitor_name} and create a structured profile. \"\n",
        "            \"Include an overview, SWOT analysis (Strengths, Weaknesses, Opportunities, Threats), and actionable insights.\\n\\n\"\n",
        "            f\"Competitor Information:\\n{competitor_info}\"\n",
        "            for competitor_name, competitor_info in zip(competitors, competitor_info_list)\n",
        "        ]\n",
        "\n",
        "        messages_batch = [\n",
        "            [{\"role\": \"system\", \"content\": \"You are a helpful assistant capable of analyzing and structuring data.\"},\n",
        "             {\"role\": \"user\", \"content\": prompt}]\n",
        "            for prompt in prompts\n",
        "        ]\n",
        "\n",
        "        texts_batch = [self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) for messages in messages_batch]\n",
        "\n",
        "        responses = self.llm.generate(texts_batch, sampling_params=self.sampling_params)\n",
        "\n",
        "        for i, response in enumerate(responses):\n",
        "            response_text = response.outputs[0].text\n",
        "            profiles.append({\n",
        "                \"competitor_name\": competitors[i],\n",
        "                \"profile\": response_text\n",
        "            })\n",
        "\n",
        "        return profiles\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "profileAgent = CompetitorProfileAgent(model_name, device=\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "d2ca0ae95bca40cdb8f51def9a44a995",
            "3e0df648d9c9415fb220bcc6a121f771",
            "ba4483e14c1946e585923dfc88b17569",
            "40f15245d45946a2a89edbb7362a5c7e",
            "621f20e4c9944818832d000ec7d0af35",
            "bd0e032e643c4eea9aba3c623663b8fb",
            "fa7fb5b1b379489d8b15bbe3a33773af",
            "d575a28e5505431a861648b3d6e3f3d9",
            "d135e1f6fbcb4c7589b62fa2b3a6d4f7",
            "76a848035cf84f1fb09d4377bc73b89d",
            "5259839d4bda478cb839273fd94116aa"
          ]
        },
        "id": "33prXP4SgJ-X",
        "outputId": "4e273444-bdc0-4391-b99e-a5d891d2e967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 01-10 09:37:24 config.py:2276] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 01-10 09:37:24 config.py:510] This model supports multiple tasks: {'embed', 'score', 'reward', 'generate', 'classify'}. Defaulting to 'generate'.\n",
            "WARNING 01-10 09:37:24 cuda.py:98] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
            "WARNING 01-10 09:37:24 config.py:642] Async output processing is not supported on the current platform type cuda.\n",
            "INFO 01-10 09:37:24 llm_engine.py:234] Initializing an LLM engine (v0.6.6.post1) with config: model='Qwen/Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-0.5B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"candidate_compile_sizes\":[],\"compile_sizes\":[],\"capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n",
            "INFO 01-10 09:37:25 model_runner.py:1094] Starting to load model Qwen/Qwen2.5-0.5B-Instruct...\n",
            "INFO 01-10 09:37:25 weight_utils.py:251] Using model weights format ['*.safetensors']\n",
            "INFO 01-10 09:37:26 weight_utils.py:296] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2ca0ae95bca40cdb8f51def9a44a995"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 01-10 09:37:27 model_runner.py:1099] Loading model weights took 0.9228 GB\n",
            "INFO 01-10 09:37:29 worker.py:241] Memory profiling takes 1.79 seconds\n",
            "INFO 01-10 09:37:29 worker.py:241] the current vLLM instance can use total_gpu_memory (14.75GiB) x gpu_memory_utilization (0.95) = 14.01GiB\n",
            "INFO 01-10 09:37:29 worker.py:241] model weights take 0.92GiB; non_torch_memory takes 0.04GiB; PyTorch activation peak memory takes 1.43GiB; the rest of the memory reserved for KV Cache is 11.62GiB.\n",
            "INFO 01-10 09:37:29 gpu_executor.py:76] # GPU blocks: 63454, # CPU blocks: 21845\n",
            "INFO 01-10 09:37:29 gpu_executor.py:80] Maximum concurrency for 32768 tokens per request: 30.98x\n",
            "INFO 01-10 09:37:30 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 2.83 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "profiles = profileAgent.generate_profile(competitors, competitor_info_list)\n",
        "\n",
        "for profile in profiles:\n",
        "    print(f\"\\nCompetitor: {profile['competitor_name']}\")\n",
        "    print(profile['profile'])\n",
        "    print(\"=\"*50, \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJoZa6Jphf_8",
        "outputId": "8d3be9c0-86bb-4020-ea5a-da4dbd2968aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 3/3 [00:15<00:00,  5.06s/it, est. speed input: 1121.34 toks/s, output: 116.60 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Competitor: Dialogflow\n",
            "Overview:\n",
            "Dialogflow is a cloud-based conversational interface platform that allows developers to create and deploy conversational interfaces for their mobile, web, and device applications. It is part of the Google Cloud Platform and offers a complete development suite with code editor, library, and tools. The platform supports multiple languages and integrations with popular conversation platforms like Google Assistant, Amazon Alexa, and Facebook Messenger.\n",
            "\n",
            "Strengths:\n",
            "1. A comprehensive development suite with code editor, library, and tools.\n",
            "2. A complete development suite that includes features like code completion, code refactoring, and code analysis.\n",
            "3. Multiple integrations with popular conversation platforms like Google Assistant, Amazon Alexa, and Facebook Messenger.\n",
            "4. A simple and easy-to-use platform for developers to create and deploy conversational interfaces.\n",
            "\n",
            "Weaknesses:\n",
            "1. It is not a single-purpose platform, and the platform is not suitable for all types of conversations.\n",
            "2. The platform is not scalable and can be difficult to maintain and update.\n",
            "\n",
            "Opportunities:\n",
            "1. The platform has the potential to become a market leader in the conversational interface market.\n",
            "2. The platform has the potential to become a market leader in the developer ecosystem, with over 15 languages and integrations with popular conversation platforms.\n",
            "\n",
            "Threats:\n",
            "1. The platform has a limited user base and is not suitable for all types of conversations.\n",
            "2. The platform has a limited support and maintenance team, which can be challenging to manage.\n",
            "\n",
            "Actionable Insights:\n",
            "1. Dialogflow has the potential to become a market leader in the conversational interface market by building a strong user base and a loyal customer base.\n",
            "2. Dialogflow has the potential to become a market leader in the developer ecosystem by building a strong ecosystem of developers and integrators.\n",
            "3. Dialogflow has the potential to become a market leader in the conversational interface market by building a strong user base and a loyal customer base.\n",
            "4. Dialogflow has the potential to become a market leader in the developer ecosystem by building a strong ecosystem of developers and integrators.\n",
            "================================================== \n",
            "\n",
            "\n",
            "\n",
            "Competitor: Alexa\n",
            "### Overview\n",
            "Alexa is a virtual assistant technology developed by Amazon that provides voice commands and voice-based services. The company has released several new devices, including the Echo, Echo Dot, Echo Studio, and Echo Show.\n",
            "\n",
            "### SWOT Analysis\n",
            "\n",
            "#### Strengths\n",
            "1. **Voice Recognition**: Alexa's ability to recognize and respond to user voice commands makes it highly effective in various contexts.\n",
            "2. **Ease of Use**: The simplicity of voice commands and the availability of Alexa Skills Kit make it easy for users to integrate voice commands into their devices.\n",
            "3. **Continued Development**: The company is committed to improving its voice recognition technology and expanding its product line.\n",
            "4. **Global Presence**: Alexa has a strong presence in various countries, including Poland, providing a global market for its voice services.\n",
            "\n",
            "#### Weaknesses\n",
            "1. **Limited Customization**: While Alexa Skills Kit allows developers to create custom voice commands, the limited customization options can limit the versatility of the platform.\n",
            "2. **High Cost**: The development and maintenance of Alexa Skills Kit and the cloud-based services can be expensive, limiting its scalability.\n",
            "3. **Regulatory Challenges**: The company faces challenges in complying with regulatory standards related to voice recognition technology and user data privacy.\n",
            "4. **Overreliance on Alexa Skills Kit**: The company may be at risk of losing its voice command capabilities if Alexa Skills Kit is discontinued or replaced by a competitor.\n",
            "\n",
            "#### Opportunities\n",
            "1. **Market Growth**: The global voice assistant market is growing, offering new opportunities for Alexa to expand its functionality and reach new markets.\n",
            "2. **New Products**: The company is introducing new voice commands and services, such as Alexa Skills and Alexa for Business, which could increase demand for its voice services.\n",
            "3. **Innovation**: The company is investing in voice recognition technology and developing new voice commands, providing an opportunity for innovation and differentiation.\n",
            "4. **Customer Preferences**: The company is focusing on customer preferences and needs, enabling it to create more personalized and engaging voice experiences.\n",
            "\n",
            "#### Threats\n",
            "1. **Regulatory Changes**: Changes in regulations related to voice recognition technology and user data privacy could affect the company's ability to operate effectively.\n",
            "2. **Competitive Pressure**: The rise of new voice assistants and competitors could challenge the company's market position and revenue streams.\n",
            "3. **Technological Disruption**: Advances in technology and the development of new voice assistants could disrupt the market, leading to a loss of market share.\n",
            "4. **User Concerns**: Users may have concerns about the security and privacy of their voice data, which could deter users from using Alexa for certain services.\n",
            "\n",
            "### Actionable Insights\n",
            "1. **Continual Improvement**: The company should continue to invest in voice recognition technology and developing new voice commands to stay competitive in the market.\n",
            "2. **User Engagement**: The company should focus on enhancing user engagement by offering more personalized and interactive voice experiences.\n",
            "3. **Regulatory Compliance**: The company should comply with regulatory standards related to voice recognition technology and user data privacy.\n",
            "4. **Market Expansion**: The company should focus on expanding its voice assistant capabilities and services to meet the increasing demand for voice assistants.\n",
            "5. **Customer Support**: The company should provide excellent customer support to address any concerns and ensure user satisfaction.\n",
            "6. **Sustainability**: The company should consider sustainability issues related to voice recognition technology and user data privacy, ensuring long-term success.\n",
            "================================================== \n",
            "\n",
            "\n",
            "\n",
            "Competitor: Microsoft Cortana\n",
            "**Competitor Information:**\n",
            "\n",
            "1. **Cortana (Microsoft)**  \n",
            "   - **Overview:** Microsoft's digital assistant that performs consumer-oriented tasks. It uses the Microsoft Bing search engine to perform a variety of tasks such as answering questions, sending emails, managing calendars, setting appointments, and more.\n",
            "   - **Strengths:** Strong natural language processing (NLP) and voice recognition capabilities. Offers a wide range of features and personalization options.\n",
            "   - **Weaknesses:** Limited support for certain services or services that do not integrate with Cortana.\n",
            "   - **Opportunities:** Diversification of services and features. Potential for integration with other Microsoft services.\n",
            "   - **Threats:** Privacy concerns, potential privacy issues, and dependency on Bing for search results.\n",
            "\n",
            "2. **Microsoft Cortana (Microsoft)**  \n",
            "   - **Overview:** Microsoft's digital assistant that performs consumer-oriented tasks. It uses the Microsoft Bing search engine to perform a variety of tasks such as answering questions, sending emails, managing calendars, setting appointments, and more.\n",
            "   - **Strengths:** Strong natural language processing (NLP) and voice recognition capabilities. Offers a wide range of features and personalization options.\n",
            "   - **Weaknesses:** Limited support for certain services or services that do not integrate with Cortana.\n",
            "   - **Opportunities:** Diversification of services and features. Potential for integration with other Microsoft services.\n",
            "   - **Threats:** Privacy concerns, potential privacy issues, and dependency on Bing for search results.\n",
            "\n",
            "3. **Microsoft Cortana (Microsoft)**  \n",
            "   - **Overview:** Microsoft's digital assistant that performs consumer-oriented tasks. It uses the Microsoft Bing search engine to perform a variety of tasks such as answering questions, sending emails, managing calendars, setting appointments, and more.\n",
            "   - **Strengths:** Strong natural language processing (NLP) and voice recognition capabilities. Offers a wide range of features and personalization options.\n",
            "   - **Weaknesses:** Limited support for certain services or services that do not integrate with Cortana.\n",
            "   - **Opportunities:** Diversification of services and features. Potential for integration with other Microsoft services.\n",
            "   - **Threats:** Privacy concerns, potential privacy issues, and dependency on Bing for search results.\n",
            "\n",
            "**Actionable Insights:**\n",
            "\n",
            "1. **Integrate with Other Microsoft Services:** By integrating Cortana with other Microsoft services, such as Office 365, Microsoft Teams, or Dynamics 365, Cortana can offer a more complete and personalized experience for users.\n",
            "2. **Offer Customizable Personalization:** By customizing Cortana's personalization options, Microsoft can create a more tailored experience for each user.\n",
            "3. **Enhance Services and Features:** By integrating Cortana with other Microsoft services, such as Office 365 or Dynamics 365, Microsoft can offer a more comprehensive and personalized experience for users.\n",
            "4. **Consider Privacy and Security:** By ensuring that Cortana's integration with other Microsoft services does not compromise user privacy and security, Microsoft can provide a secure and reliable experience for its users.\n",
            "5. **Diversify Services and Features:** By offering a variety of services and features that can be integrated with Cortana, Microsoft can create a more complete and personalized experience for its users.\n",
            "================================================== \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del profileAgent"
      ],
      "metadata": {
        "id": "Zs6akiZOaTR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "import torch\n",
        "\n",
        "class ReportGeneratorAgent:\n",
        "    def __init__(self, model_name=\"Qwen/Qwen2.5-0.5B-Instruct\", tensor_parallel_size=1, max_model_len=32768, max_tokens=32768, temperature=0.7, top_p=0.9, device=\"cuda\"):\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        self.llm = LLM(\n",
        "            model_name,\n",
        "            tensor_parallel_size=tensor_parallel_size,\n",
        "            gpu_memory_utilization=0.95,\n",
        "            trust_remote_code=True,\n",
        "            dtype=\"half\",\n",
        "            enforce_eager=True,\n",
        "            max_model_len=max_model_len,\n",
        "            device=device\n",
        "        )\n",
        "        self.tokenizer = self.llm.get_tokenizer()\n",
        "\n",
        "        self.sampling_params = SamplingParams(\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "\n",
        "    def generate_report(self, competitors, profiles):\n",
        "\n",
        "        prompt = (\n",
        "            f\"Based on the following competitor profiles, generate a detailed competitor analysis report.\\n\"\n",
        "            f\"Include an introduction, an overview of each competitor, feature comparisons, and strategic recommendations.\\n\"\n",
        "            \"The report should be structured as follows:\\n\"\n",
        "            \"1. Introduction\\n\"\n",
        "            \"2. Competitor Overview\\n\"\n",
        "            \"3. Feature Comparisons\\n\"\n",
        "            \"4. Strategic Recommendations\\n\\n\"\n",
        "            \"Competitor Profiles:\\n\"\n",
        "        )\n",
        "\n",
        "        for competitor, profile in zip(competitors, profiles):\n",
        "            prompt += f\"\\n{competitor}: {profile}\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in competitor analysis and report generation.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "        text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "        response = self.llm.generate([text], sampling_params=self.sampling_params)\n",
        "\n",
        "        report = response[0].outputs[0].text\n",
        "\n",
        "        return report\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "reportAgent = ReportGeneratorAgent(model_name, device=\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "b0b7cc99860c440992ec86102150f3ff",
            "22f2a0e9f9ff4277b7895009862296b8",
            "bd6362cdbbff484b8e40e7580df02c0f",
            "9c017b7c32b94de49cd99bd676038d05",
            "b32b48d4cc9f455fbc64ca5373916248",
            "fd993ccf2c7b4685b954f76c59814e68",
            "b30d595c298a4114a98fbec6cb9401bf",
            "787b7fc595fe4b62becf15c6857a02ef",
            "085c25aceb194fec933a001d7f3bbc99",
            "dbc4a977c65e4418999a0de9cebb149d",
            "96ce228d6de645eda1a8726cef3fdafa"
          ]
        },
        "id": "N1cWCiMqiqX3",
        "outputId": "4fd3d401-ce70-4301-aef2-846804e02efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 01-10 09:37:49 config.py:2276] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 01-10 09:37:49 config.py:510] This model supports multiple tasks: {'embed', 'score', 'reward', 'generate', 'classify'}. Defaulting to 'generate'.\n",
            "WARNING 01-10 09:37:49 cuda.py:98] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
            "WARNING 01-10 09:37:49 config.py:642] Async output processing is not supported on the current platform type cuda.\n",
            "INFO 01-10 09:37:49 llm_engine.py:234] Initializing an LLM engine (v0.6.6.post1) with config: model='Qwen/Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen/Qwen2.5-0.5B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"candidate_compile_sizes\":[],\"compile_sizes\":[],\"capture_sizes\":[],\"max_capture_size\":0}, use_cached_outputs=False, \n",
            "INFO 01-10 09:37:50 model_runner.py:1094] Starting to load model Qwen/Qwen2.5-0.5B-Instruct...\n",
            "INFO 01-10 09:37:50 weight_utils.py:251] Using model weights format ['*.safetensors']\n",
            "INFO 01-10 09:37:50 weight_utils.py:296] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0b7cc99860c440992ec86102150f3ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 01-10 09:37:52 model_runner.py:1099] Loading model weights took 0.9228 GB\n",
            "INFO 01-10 09:37:54 worker.py:241] Memory profiling takes 1.77 seconds\n",
            "INFO 01-10 09:37:54 worker.py:241] the current vLLM instance can use total_gpu_memory (14.75GiB) x gpu_memory_utilization (0.95) = 14.01GiB\n",
            "INFO 01-10 09:37:54 worker.py:241] model weights take 0.92GiB; non_torch_memory takes 0.04GiB; PyTorch activation peak memory takes 1.43GiB; the rest of the memory reserved for KV Cache is 11.62GiB.\n",
            "INFO 01-10 09:37:54 gpu_executor.py:76] # GPU blocks: 63454, # CPU blocks: 21845\n",
            "INFO 01-10 09:37:54 gpu_executor.py:80] Maximum concurrency for 32768 tokens per request: 30.98x\n",
            "INFO 01-10 09:37:55 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 2.78 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report = reportAgent.generate_report(competitors, profiles)\n",
        "print(report)\n",
        "with open(\"competitor_analysis_report.txt\", \"w\") as f:\n",
        "    f.write(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7NYjjG1j8Wf",
        "outputId": "5c166aaf-5fb2-433c-9efd-1b8615a758b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:16<00:00, 16.06s/it, est. speed input: 124.00 toks/s, output: 52.75 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Competitor Analysis Report\n",
            "\n",
            "#### Introduction\n",
            "\n",
            "Dialogflow is a cloud-based conversational interface platform developed by Google that offers a comprehensive development suite with code editor, library, and tools. It supports multiple languages and integrations with popular conversation platforms like Google Assistant, Amazon Alexa, and Facebook Messenger. The platform has a strong development suite with features like code completion, code refactoring, and code analysis, making it suitable for developers to create and deploy conversational interfaces.\n",
            "\n",
            "Alexa, on the other hand, is a virtual assistant technology developed by Amazon that provides voice commands and voice-based services. The company has released several new devices, including the Echo, Echo Dot, Echo Studio, and Echo Show. Alexa offers a wide range of features and personalization options, making it a popular choice for voice assistants.\n",
            "\n",
            "Microsoft Cortana, on the other hand, is a digital assistant that performs consumer-oriented tasks using the Microsoft Bing search engine. It offers a wide range of features and personalization options, making it a popular choice for voice assistants.\n",
            "\n",
            "### Feature Comparisons\n",
            "\n",
            "#### Dialogflow\n",
            "- **Voice Recognition**: Highly effective in various contexts, offering a seamless user experience.\n",
            "- **Ease of Use**: A simple and easy-to-use platform for developers to create and deploy conversational interfaces.\n",
            "- **Continued Development**: The company is committed to improving its voice recognition technology and expanding its product line.\n",
            "- **Global Presence**: Provides a global market for its voice services.\n",
            "\n",
            "#### Alexa\n",
            "- **Voice Recognition**: Strong, offering a seamless user experience.\n",
            "- **Ease of Use**: A simple and easy-to-use platform for developers to create and deploy conversational interfaces.\n",
            "- **Continued Development**: The company is committed to improving its voice recognition technology and expanding its product line.\n",
            "- **Global Presence**: Provides a global market for its voice services.\n",
            "\n",
            "#### Microsoft Cortana\n",
            "- **Voice Recognition**: Strong, offering a seamless user experience.\n",
            "- **Ease of Use**: A simple and easy-to-use platform for developers to create and deploy conversational interfaces.\n",
            "- **Continued Development**: The company is committed to improving its voice recognition technology and expanding its product line.\n",
            "- **Global Presence**: Provides a global market for its voice services.\n",
            "\n",
            "### Strategic Recommendations\n",
            "\n",
            "1. **Expand Voice Commands and Services**: By integrating Alexa with other Microsoft services, such as Office 365, Microsoft Teams, or Dynamics 365, the company can offer a more complete and personalized experience for users.\n",
            "\n",
            "2. **Enhance Personalization**: By customizing Cortana's personalization options, Microsoft can create a more tailored experience for each user.\n",
            "\n",
            "3. **Integrate with Other Microsoft Services**: By integrating Cortana with other Microsoft services, such as Office 365 or Dynamics 365, the company can offer a more comprehensive and personalized experience for users.\n",
            "\n",
            "4. **Consider Privacy and Security**: By ensuring that Cortana's integration with other Microsoft services does not compromise user privacy and security, Microsoft can provide a secure and reliable experience for its users.\n",
            "\n",
            "5. **Diversify Services and Features**: By offering a variety of services and features that can be integrated with Cortana, Microsoft can create a more complete and personalized experience for its users.\n",
            "\n",
            "6. **Enhance Customization**: By offering more personalization options for Cortana, Microsoft can create a more tailored experience for each user.\n",
            "\n",
            "7. **Offer Customizable Personalization**: By customizing Cortana's personalization options, Microsoft can create a more personalized experience for each user.\n",
            "\n",
            "8. **Ensure Regulatory Compliance**: By ensuring that Cortana's integration with other Microsoft services does not compromise user privacy and security, Microsoft can provide a secure and reliable experience for its users.\n",
            "\n",
            "9. **Provide Excellent Customer Support**: By providing excellent customer support to address any concerns and ensure user satisfaction, Microsoft can address any concerns and ensure user satisfaction.\n",
            "\n",
            "10. **Diversify Services and Features**: By offering a variety of services and features that can be integrated with Cortana, Microsoft can create a more complete and personalized experience for its users.\n",
            "\n",
            "11. **Consider Sustainability**: By considering sustainability issues related to voice recognition technology and user data privacy, Microsoft can ensure long-term success.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfkit\n",
        "import markdown\n",
        "\n",
        "def save_to_pdf(report_markdown, pdf_file_name=\"competitor_analysis_report.pdf\", input_query=None):\n",
        "    if input_query:\n",
        "        pdf_file_name = f\"{input_query.replace(' ', '_')}_{pdf_file_name}\"\n",
        "\n",
        "    report_markdown = preprocess_markdown(report_markdown)\n",
        "\n",
        "    report_html = markdown.markdown(report_markdown)\n",
        "\n",
        "    options = {\n",
        "        'page-size': 'A4',\n",
        "        'encoding': \"UTF-8\",\n",
        "    }\n",
        "\n",
        "    pdfkit.from_string(report_html, pdf_file_name, options=options)\n",
        "    print(f\"Report saved as {pdf_file_name}\")\n",
        "\n",
        "def preprocess_markdown(markdown_text):\n",
        "    lines = markdown_text.splitlines()\n",
        "    processed_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Ensure proper spacing before list items\n",
        "        if line.strip().startswith(\"-\") and not line.startswith(\" \"):\n",
        "            processed_lines.append(\"\\n\" + line)  # Add a blank line before the list item\n",
        "        else:\n",
        "            processed_lines.append(line)\n",
        "\n",
        "    return \"\\n\".join(processed_lines)"
      ],
      "metadata": {
        "id": "K5iNSambo0fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_to_pdf(report, input_query=input_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcT-_5K6o35e",
        "outputId": "0a28a94b-8fb1-4db9-a912-de24cf52834d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report saved as chatbot_for_customer_suppor_competitor_analysis_report.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del reportAgent"
      ],
      "metadata": {
        "id": "fhiPRED5qNXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4-hAokWSoWm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}